{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4ffe2d-707c-4568-838b-0a1912c64430",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.signal as scisig\n",
    "import spectrally_regularised_LVMs as srLVMs\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "from axs_fixer import fix\n",
    "\n",
    "MEDIUM_SIZE = 30\n",
    "BIGGER_SIZE = 40\n",
    "\n",
    "plt.rc(\"font\", size=MEDIUM_SIZE)  # controls default text sizes\n",
    "plt.rc(\"axes\", titlesize=MEDIUM_SIZE)  # fontsize of the axes title\n",
    "plt.rc(\"axes\", labelsize=MEDIUM_SIZE)  # fontsize of the x and y labels\n",
    "plt.rc(\"xtick\", labelsize=MEDIUM_SIZE)  # fontsize of the tick labels\n",
    "plt.rc(\"ytick\", labelsize=MEDIUM_SIZE)  # fontsize of the tick labels\n",
    "plt.rc(\"legend\", fontsize=MEDIUM_SIZE)  # legend fontsize\n",
    "plt.rc(\"figure\", titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "plt.rc(\"figure\", figsize=(16, 10), dpi=600)\n",
    "plt.rc(\"savefig\", dpi=600, format=\"pdf\")\n",
    "plt.rc(\"grid\", linestyle=\"--\")\n",
    "\n",
    "matplotlib.rcParams.update(\n",
    "    {  # Use mathtext, not LaTeX\n",
    "        \"text.usetex\": False,\n",
    "        # Use the Computer modern font\n",
    "        \"font.family\": \"serif\",\n",
    "        \"font.serif\": \"cmr10\",\n",
    "        \"mathtext.fontset\": \"cm\",\n",
    "        # Use ASCII minus\n",
    "        \"axes.unicode_minus\": False,\n",
    "    }\n",
    ")\n",
    "\n",
    "plt.ioff()\n",
    "\n",
    "print(f\"Package version: {srLVMs.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dc6c67-ca7d-46a6-b9f9-5f1add58fc16",
   "metadata": {},
   "source": [
    "# Example one\n",
    "\n",
    "In the first example, the PCA objective function is expressed as a objective function for the *spectrally-regularised-LVMs* package using a symbolic representation and through an explicit representation. The PCA objective function is given by\n",
    "$$ \\mathcal{L}_{model} = \\mathbb{E}_{\\mathbf{x} \\sim p(\\mathbf{x})} \\{ (\\mathbf{w}_i^T \\mathbf{x})^2 \\},$$\n",
    "where it is assumed that $\\mathbf{x}$ is zero-mean."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf14d6c8-feea-49a8-b768-428800e9f788",
   "metadata": {},
   "source": [
    "## Symbolic representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f785bf29-3aba-4576-97f3-6873b06f827e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy as sp\n",
    "import spectrally_regularised_LVMs as srLVMs\n",
    "\n",
    "# Symbolic cost function implementation\n",
    "cost_inst = srLVMs.SymbolicCost() \n",
    "\n",
    "z, j, n = cost_inst.get_symbolic_parameters()\n",
    "\n",
    "loss = -1/n * sp.Sum((z[j])**2, (j))\n",
    "\n",
    "cost_inst.set_cost(loss) \n",
    "\n",
    "# Visualise the loss\n",
    "sp.pretty_print(loss)\n",
    "\n",
    "# Visualise the properties of the indexed variables\n",
    "print(z[j].shape, z[j].ranges)\n",
    "print(j)\n",
    "print(n) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbf913f-8e67-435f-918a-2890cf38fda9",
   "metadata": {},
   "source": [
    "## Explicit representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4b7bbd-2bf8-4eeb-a594-f04e66cb80d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import spectrally_regularised_LVMs as srLVMs\n",
    "\n",
    "# Explicit cost function implementation\n",
    "cost_inst = srLVMs.ExplicitCost()\n",
    "\n",
    "obj = lambda X, w, z: -1 * np.mean((X @ w)**2, axis = 0)\n",
    "grad = lambda X, w, z: -2 * np.mean((X @ w) * X, axis = 0, \n",
    "                                    keepdims=True).T\n",
    "hess = lambda X, w, z: -2 / X.shape[0] * (X.T @ X)\n",
    "\n",
    "cost_inst.set_cost(obj)\n",
    "cost_inst.set_gradient(grad)\n",
    "cost_inst.set_hessian(hess) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849dd4f3-edd8-4a34-afa6-6d51d82d9fee",
   "metadata": {},
   "source": [
    "## Performing parameter estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cca294-f9da-423c-ad04-93c691af23a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import spectrally_regularised_LVMs as srLVMs\n",
    "\n",
    "# Define a toy signal\n",
    "x_signal = np.random.randn(10000)\n",
    "\n",
    "# Define the cost function instance\n",
    "cost_inst = ...\n",
    "\n",
    "# Define the model\n",
    "model_inst = srLVMs.LinearModel(n_sources = 5,\n",
    "                                cost_instance = cost_inst, \n",
    "                                Lw = 256,\n",
    "                                Lsft = 1) \n",
    "\n",
    "# Estimate the model parameters\n",
    "model_inst.fit(x_signal)\n",
    "\n",
    "# Obtain the latent representation Z\n",
    "Z = model_inst.transform(x_signal)\n",
    "\n",
    "# Obtain the recovered representation of X\n",
    "X_recon = model_inst.inverse_transform(Z) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44315288-3190-4600-b59c-18d29c1583b6",
   "metadata": {},
   "source": [
    "# Example two\n",
    "\n",
    "In the second example, the negentropy-based objective function common to ICA is used to estimate the model parameters for a signal from the IMS dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e7c887-5569-4b57-940b-50661087d134",
   "metadata": {},
   "source": [
    "## Using the package - a full example for a signal from the IMS dataset (with spectral regularisation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23e955d-8e6e-4643-81d4-6c3b52a508b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import spectrally_regularised_LVMs as srLVMs\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "# Step 1: Load in the time series signal\n",
    "data_dict = np.loadtxt(\"./2004.02.17.07.12.39\") # This is the IMS dataset signal stored in the '/Examples/' directory in the Github repository\n",
    "x_signal = data_dict[:, 0]\n",
    "Fs = 20480\n",
    "\n",
    "# Step 2: Define the cost function instance\n",
    "cost_inst = srLVMs.NegentropyCost(\"exp\", {\"alpha\":1}) # negentropy objective\n",
    "\n",
    "# Step 3: Define the model\n",
    "model_inst = srLVMs.LinearModel(n_sources = 10,\n",
    "                                cost_instance = cost_inst, \n",
    "                                Lw = 256,\n",
    "                                Lsft = 1,\n",
    "                                sumt_flag=True,\n",
    "                                verbose = True,\n",
    "                                organise_by_kurt=True)\n",
    "\n",
    "# Step 4: Estimate the model parameters\n",
    "model_inst.fit(x_signal)\n",
    "\n",
    "# Step 5: Obtain the latent representation Z\n",
    "Z = model_inst.transform(x_signal)\n",
    "\n",
    "# Step 6: Obtain the recovered representation of X\n",
    "X_recon = model_inst.inverse_transform(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc63744-55ac-43b6-82a5-fd458a4a0c1f",
   "metadata": {},
   "source": [
    "## Using the package - a full example for a signal from the IMS dataset (without spectral regularisation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fcf0a8-5687-4bd5-9359-81ad7583d412",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spectrally_regularised_LVMs as srLVMs\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "# Step 1: Load in the time series signal\n",
    "data_dict = np.loadtxt(\"./2004.02.17.07.12.39\") # This is the IMS dataset signal stored in the '/Examples/' directory in the Github repository\n",
    "x_signal = data_dict[:, 0]\n",
    "Fs = 20480\n",
    "\n",
    "# Step 2: Define the cost function instance\n",
    "cost_inst = srLVMs.NegentropyCost(\"exp\", {\"alpha\":1}) # negentropy objective\n",
    "\n",
    "# Step 3: Define the model\n",
    "model_inst = srLVMs.LinearModel(n_sources = 10,\n",
    "                                cost_instance = cost_inst, \n",
    "                                Lw = 256,\n",
    "                                Lsft = 1,\n",
    "                                sumt_flag=False,\n",
    "                                alpha_reg=0,\n",
    "                                verbose = True,\n",
    "                                organise_by_kurt=True)\n",
    "\n",
    "# Step 4: Estimate the model parameters\n",
    "model_inst.fit(x_signal)\n",
    "\n",
    "# Step 5: Obtain the latent representation Z\n",
    "Z2 = model_inst.transform(x_signal)\n",
    "\n",
    "# Step 6: Obtain the recovered representation of X\n",
    "X_recon = model_inst.inverse_transform(Z2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82139a3-5b39-4d28-8410-bd53e83523fa",
   "metadata": {},
   "source": [
    "## Visualisation - IMS signal spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c782963b-ebfa-4cdf-b0f4-7a11fc4c3e17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "colors = [\"#00b0f9\", \"#bfacdc\", \"#d0bdd5\", \"#ffa59e\", \"#dd4c65\",\"#93003a\"]\n",
    "fig, ax = plt.subplots(figsize = (12, 10))\n",
    "\n",
    "n = len(x_signal)\n",
    "fft_freq = np.fft.fftfreq(n, 1/Fs)[:n//2]\n",
    "fft_val = 2/n * np.abs(np.fft.fft(x_signal)[:n//2])\n",
    "ax.plot(fft_freq, fft_val, lw = 0.5, color = \"k\", label = \"Record 540\")\n",
    "ax.set_xlabel(\"Frequency (Hz)\")\n",
    "ax.set_ylabel(\"Magnitude\")\n",
    "ax.grid()\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "# plt.savefig(\"./signal.pdf\")\n",
    "# plt.savefig(\"./signal.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2624552b-6232-4529-9a3d-b6c9d7062ded",
   "metadata": {},
   "source": [
    "## Visualisation - Latent source spectra and SES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1271e2-9818-4eb0-bc96-8515ef117822",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "colors = [\"#00b0f9\", \"#bfacdc\", \"#d0bdd5\", \"#ffa59e\", \"#dd4c65\",\"#93003a\"]\n",
    "\n",
    "fig, ax = plt.subplots(5, 2, figsize = (20, 24))\n",
    "\n",
    "n = Z.shape[0]\n",
    "fft_freq = np.fft.fftfreq(n, 1/Fs)[:n//2]\n",
    "\n",
    "for cnt in range(5):\n",
    "    fft_mag = 2/n * np.abs(np.fft.fft(Z[:, cnt])[:n//2])\n",
    "    fft_mag2 = 2/n * np.abs(np.fft.fft(Z2[:, cnt])[:n//2])\n",
    "\n",
    "    ax[cnt, 0].plot(fft_freq, \n",
    "                    fft_mag2, \n",
    "                    color = \"r\", \n",
    "                    linewidth = 0.5, \n",
    "                    label = rf\"Source {cnt + 1} without $\\mathcal{'{L}'}_{'{sr}'}$\")\n",
    "    \n",
    "    ax[cnt, 1].plot(fft_freq, \n",
    "                    fft_mag, \n",
    "                    color = \"b\", \n",
    "                    linewidth = 0.5, \n",
    "                    label = rf\"Source {cnt + 1} with $\\mathcal{'{L}'}_{'{sr}'}$\")\n",
    "    # ax[cnt, 1].set_xlim(-10, 2000)\n",
    "\n",
    "for cnt, axs in enumerate(ax.flatten()):\n",
    "    axs.set_xlabel(\"Frequency (Hz)\")\n",
    "    axs.set_ylabel(\"Magnitude\")\n",
    "    axs.grid()\n",
    "    axs.legend()\n",
    "    fix(axs, minor_flag=True, flag_3d=False)\n",
    "\n",
    "fig.tight_layout()\n",
    "    \n",
    "# plt.savefig(\"./sources.pdf\")\n",
    "# plt.savefig(\"./sources.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f968a11b-6efc-4c1a-acf5-a28ad5223f24",
   "metadata": {},
   "source": [
    "# Example three\n",
    "\n",
    "In this example, different methods of cost function implementation are demonstrated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc986479-5250-4bbf-b816-d8643e569cc0",
   "metadata": {},
   "source": [
    "## Method one: Symbolically defined objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd880460-20ba-4df9-8e12-409f698eb90f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define imports\n",
    "import spectrally_regularised_LVMs as srLVMs\n",
    "import numpy as np\n",
    "import sympy as sp\n",
    "np.random.seed(0)\n",
    "\n",
    "# Setup general matrices\n",
    "X = np.random.randn(500, 16)\n",
    "X -= np.mean(X, axis = 0, keepdims=True)\n",
    "w = np.random.randn(16, 1)\n",
    "z = X @ w\n",
    "\n",
    "# Initialise the cost function instance\n",
    "cost_inst = srLVMs.SymbolicCost(use_hessian=True,\n",
    "                                verbose=True,\n",
    "                                finite_diff_flag=False)\n",
    "\n",
    "z_sp, j, n = cost_inst.get_symbolic_parameters()\n",
    "\n",
    "loss = -1/n * sp.Sum((z_sp[j])**2, (j))\n",
    "\n",
    "cost_inst.set_cost(loss)\n",
    "display(loss)\n",
    "\n",
    "# Check that the gradient and Hessian make sense\n",
    "res_grad = cost_inst.check_gradient(X, w, z, 1e-4)\n",
    "res_hess = cost_inst.check_hessian(X, w, z, 1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b5dd27-61f6-448e-8012-bb1678805d15",
   "metadata": {},
   "source": [
    "## Method two: Explicitly defined objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fef656-f94f-484f-b186-114d5c26f249",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define imports\n",
    "import spectrally_regularised_LVMs as srLVMs\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "# Setup general X matrix\n",
    "X = np.random.randn(500, 16)\n",
    "X -= np.mean(X, axis = 0, keepdims=True)\n",
    "w = np.random.randn(16, 1)\n",
    "z = X @ w\n",
    "\n",
    "# Initialise the cost function instance\n",
    "cost_inst = srLVMs.ExplicitCost(use_hessian=True,\n",
    "                                verbose=True,\n",
    "                                finite_diff_flag=False)\n",
    "\n",
    "# Implement the objective function, gradient and Hessian\n",
    "def loss(X, w, z):\n",
    "    return -1 * np.mean((X @ w) ** 2, axis=0)\n",
    "\n",
    "def grad(X, w, z):\n",
    "    return -2 * np.mean(z * X, axis=0, keepdims=True).T\n",
    "\n",
    "def hess(X, w, z):\n",
    "    return -2 / X.shape[0] * (X.T @ X)\n",
    "\n",
    "# Set the properties\n",
    "cost_inst.set_cost(loss)\n",
    "cost_inst.set_gradient(grad)\n",
    "cost_inst.set_hessian(hess)\n",
    "\n",
    "# Check that the gradient and Hessian make sense\n",
    "res_grad = cost_inst.check_gradient(X, w, z, 1e-4)\n",
    "res_hess = cost_inst.check_hessian(X, w, z, 1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cc9326-ee60-4588-9413-e641b5007f3a",
   "metadata": {},
   "source": [
    "## Method 3: In-built variance objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e23fd40-122f-427a-8779-3fe2e3b8ec85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define imports\n",
    "import spectrally_regularised_LVMs as srLVMs\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "# Setup general matrices\n",
    "X = np.random.randn(500, 16)\n",
    "X -= np.mean(X, axis = 0, keepdims=True) # De-mean the data\n",
    "w = np.random.randn(16, 1)\n",
    "z = X @ w\n",
    "\n",
    "# Initialise the cost function instance\n",
    "cost_inst = srLVMs.VarianceCost(use_hessian=True,\n",
    "                                verbose=True,\n",
    "                                finite_diff_flag=False)\n",
    "\n",
    "# Check that the gradient and Hessian make sense\n",
    "res_grad = cost_inst.check_gradient(X, w, z, 1e-4)\n",
    "res_hess = cost_inst.check_hessian(X, w, z, 1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d32cba-e2b1-428b-b08c-17ed62a8c92d",
   "metadata": {},
   "source": [
    "## Method 3: In-built negentropy objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14e0090-61fa-4e93-b074-d6836dfa5282",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define imports\n",
    "import spectrally_regularised_LVMs as srLVMs\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "# Setup general matrices\n",
    "X = np.random.randn(500, 16)\n",
    "X -= np.mean(X, axis = 0, keepdims=True) # De-mean the data\n",
    "w = np.random.randn(16, 1)\n",
    "z = X @ w\n",
    "\n",
    "## Initialise the cost function instance\n",
    "cost_inst = srLVMs.NegentropyCost(source_name=\"exp\",\n",
    "                                  source_params={\"alpha\": 1},\n",
    "                                  use_approx=False,\n",
    "                                  use_hessian=True,\n",
    "                                  verbose = True,\n",
    "                                  finite_diff_flag=False)\n",
    "\n",
    "## Check that the gradient and Hessian make sense\n",
    "res_grad = cost_inst.check_gradient(X, w, z, 1e-4)\n",
    "res_hess = cost_inst.check_hessian(X, w, z, 1e-4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter_kernel",
   "language": "python",
   "name": "jupyter_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
